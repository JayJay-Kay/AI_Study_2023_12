<!DOCTYPE html>
<html>
<head>
  <title>챕터 8</title>
</head>

<body>
<h2>챕터 8: 감정 분석에 머신 러닝 적용</h2>

- 의견 분석(opinion mining)/감성 분석(sentiment analysis) <br>
  - 사람들의 의견, 감정, 태도와 같은 주관적 정보를 객관적인 형태로 추출하는 것 <br>
  - 분석 단계 <br>
      1. 극성 분석(polarity analysis) <br>
        - 텍스트가 긍정, 부정, 중립인지 판단 <br>
      2. 감정 분석(Emotion Analysis) <br>
        - 텍스트의 특정 감정 탐지 (예시: 행복, 슬픔, 분노) <br>
      3. 주제별 의견 분석 (Aspect-based Opinion Mining) <br>
        - 더 깊이 들어가서 사람들의 의견 분석 (맛집의 음식 맛, 서비스 퀄리티 분석) <br>

- BoW(Bag of Words) 모델<br>
  - 텍스트 문서와 같은 범주형 데이터를 수치화 시키는 것 (무슨 단어가 몇번 나왔는지 등등)<br>
  - 작동 방식<br>
    - 1. 어휘 사전 생성 (문서에 사용되는 단어 목록)<br>
    - 2. 특성 벡터 생성 (문서에 특정 단어가 몇번 나왔는지 계사하는 것)<br>
  - 활용 예시<br>
    - 1. 텍스트 분류 (스팸 감지, 뉴스 분류 등등)<br>
    - 2. 정보 검색 (특정 키워드가 포함된 문서 검색)<br>
    - 3. 문서 유사성 평가 (대학 논문 표절 감지)<br>
  - 장단점<br>
    - 장점: 구현이 간단하고 효율적<br>
    - 단점: 단어의 순서 정보를 잃어버림, 텍스트의 문맥을 제대로 이해 못할수도 있음<br>

- tf-idf
  - 자주 등장하는 단어일수록 유용한 정보를 가지고 있지 않기 때문에 가중치를 낮출 필요가 있음

  - 로지스틱 회귀 모델 훈련 (문서 분류)<br>
    - 결론부터<br>
      - 1. 교차 검증 정확도: 89.7%<br>
      - 2. 테스트 데이터셋 정확도: 89.9%<br>
      - 이 머신러닝 모델은 89.9% 정확도로 영화 리뷰가 긍정인지 부정인지 분류 및 예측 가능 <br>
    - 모델 훈련 방식 <br>
      - 1. 데이터셋 준비 (25,000개의 훈련 데이터셋, 25,000개의 테스트 데이터셋) <br>
      - 2. 모델 구성 및 훈련 <br>
        - TfidfVectorizer와 로지스틱 회귀를 결합한 파이프라인 구성 <br>
        - GridSearchCV를 사용하여 5-겹 곛ㅇ별 교차 검증으로 최적의 매개변수 조합 발견 <br>
    - 단점: 메모리 사용 많음 = 계산 비용 많음 (위의 예시에서도 5만개의 데이터 처리) <br>
    - 해결책: 외부 메모리 학습 <br>
      
  - 외부 메모리 학습 <br>
  - <img src="https://github.com/JayJay-Kay/AI_Study_2023_12/assets/110762505/07acc6af-8d4f-40a6-8f4b-adc57afd66f3" width="500"> <br>
    - 데이터를 쪼개서 조금씩 학습시키기(?) <br>
    - 예시: 45개의 미니 배치 (각각 1000개 문서)를 사용하여 모델을 점진적으로 학습 후 마지막 5000개로 모델의 성능 평가 <br>
    - 정확도는 86.8%로 로지스틱 회귀 모델 보다 낮지만 메모리 효률적 = 가성비! <br>
    - 단점: 나쁜 데이터가 들어왔을때 한번에 줄어드는게 아니라 점진적으로 줄어듬 (변화 감지가 느리다?) <br>
      - 나쁜 데이터로 훈련 모델 수정 필요시 파악하는게 힘들수도 있음 <br>
    
  - 잠재 디리클레 할당 (LDA = Latent Dirichlet Allocation)
  ![image](https://github.com/JayJay-Kay/AI_Study_2023_12/assets/110762505/63a9952b-fd3e-4265-99ad-2cc35ce010ca)
    - 비지도 학습 토픽 모델링 알고리즘
      - 토픽 모델링: 레이블이 없는 문서 텍스트에 토픽을 할당하는 기술
    - 문서에 자주 등장하는 단어의 그룹을 찾아내는 확률적 생성 모델
    - 구현 방식
      - 사이킷런의 LatenDirichletAllocation 클래스를 사용
      - BoW행렬 생성, 최대 5000개의 단어만 사용
      - LDA학습 진행으로 10개의 토픽 분류
</body>
 </html>
